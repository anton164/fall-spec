{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from notebook_utils import resolve_paths_from_parent_directory\n",
    "resolve_paths_from_parent_directory()\n",
    "# auto reload notebook deps\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Goal: Hash semantically similar tweets to feature buckets in MStream\n",
    "\n",
    "### Question: How can we represent tweet content such that semantically similar tweets hash to the same buckets?\n",
    "\n",
    "### Approach\n",
    "1) Compute embedding(s) of a tweet\n",
    "2) Project embedding to a single dimension using K hash functions\n",
    "3) \n",
    "\n",
    "### Key questions\n",
    "- Should a tweet's content map to 1 or multiple embeddings before hashing?\n",
    "- Should tweet content be represented as a single or multiple features in MStream?\n",
    "\n",
    "### Experiments\n",
    "- Use various embedding functions for content\n",
    "- Projection of embedding function to a hash function\n",
    "- Use various hash functions"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "# load dataset\n",
    "import pandas as pd\n",
    "from utils.dataset import load_tweet_dataset\n",
    "\n",
    "df_tweets = load_tweet_dataset(\"../data/labeled_datasets/CentralParkNYC-2021-01-27-2021-02-06.json\")\n",
    "\n",
    "df_tweets = df_tweets[pd.isna(df_tweets.retweeted)]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "df_tweets.sort_values(\"retweet_count\", ascending=False)\n",
    "\n",
    "text_1 = \"There is so much snow in Central Park! Did you check it out?\"\n",
    "text_2 = \"It's freezing cold today!\"\n",
    "text_3 = \"Looks like fun! @Test\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1) Normalize tweet text\n",
    "\n",
    "Lemmatization, stemming, removal of stopwords, etc."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "def normalize_tweet_text(tweet_text):\n",
    "    return tweet_text.lower()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2) Compute tweet embedding(s) of normalized tweet text"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def tweet_embedding(normalized_tweet_text):\n",
    "    # TODO\n",
    "    pass"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3) Compute hash function of tweet embeddings\n",
    "\n",
    "We map each vector to a real value associated with that vector. \n",
    "\n",
    "**Goal:** similar vectors should map to similar numbers."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# K random projections"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit ('spec-project': conda)"
  },
  "interpreter": {
   "hash": "d5626e6117a626f228c3b35b757f4e3d945537012d8c7ec5db5088829d27e251"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}